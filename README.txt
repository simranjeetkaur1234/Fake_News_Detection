# Fake News Detection Project

This repository contains the code and documentation for a study on detecting fake news using machine learning (ML) and deep learning (DL) models. The project compares the efficacy of traditional ML models with advanced DL models to identify deceptive content on social media platforms.

## Project Overview

The aim of this project is to explore various ML and DL techniques to accurately detect fake news articles. By employing models such as Naive Bayes, Logistic Regression, Convolutional Neural Networks (CNNs), and Long Short-Term Memory networks (LSTMs), this research seeks to understand which models perform best in differentiating between true and fabricated content.

## Dataset

The research utilizes the ISOT Fake News Dataset, which is sourced from Mendeley Data. This dataset is crucial for training and evaluating the performance of the machine learning models used in this study.

### Dataset Details

- **Source**: Mendeley Data - ISOT Fake News Dataset
- **Link**:https://data.mendeley.com/datasets/945z9xkc8d/1
- **Citation**: H. Ahmed, I. Traore, S. Saad, "Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques," in: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 2017, pp. 127â€“138. DOI: [Link to DOI]
- **Description**: The dataset includes a balanced collection of fake and real news articles, making it a valuable resource for training models to accurately identify deceptive information. The dataset is divided into training and testing sets with an 80:20 split to facilitate rigorous model evaluation.
## How It Works
- We use models like Naive Bayes, Logistic Regression, CNN, and LSTM.
- The project is based on a dataset that includes both real and fake news articles.

## Files in This Repository
- `data/`: Contains the dataset used for training and testing the models.
- `models/`: Stores the trained models (note: large files might not be uploaded here).
- `notebooks/`: Jupyter notebooks with all the coding and testing.
- `src/`: Python scripts for data preparation, model training, and evaluation.
- `requirements.txt`: A list of Python packages needed to run the project.

## Getting Started
To get started with this project:
1. Clone this repository.
2. Install required Python packages: `pip install -r requirements.txt`.
3. Run the Jupyter notebook in the `notebooks/` directory to train the models.

## How to Contribute
Feel free to fork this repository, make changes, and submit a pull request if you have improvements or new ideas.



## Acknowledgments
- Thanks to everyone who contributed to developing the models and documentation.
- Thanks to Mendeley Data for providing the dataset we used.

